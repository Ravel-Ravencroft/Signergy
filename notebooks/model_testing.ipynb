{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Up and DF Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/Michael/Downloads/Final-Year-Project/data')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import BatchNormalization, Conv2D, Conv3D, ConvLSTM2D, Dense, Dropout, Flatten, LSTM, MaxPooling2D, MaxPooling3D, TimeDistributed\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "DATA_DIR = (Path().parent / \"../data\").resolve()\n",
    "DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype   \n",
      "---  ------     --------------  -----   \n",
      " 0   file_name  50 non-null     object  \n",
      " 1   sign       50 non-null     category\n",
      " 2   left       50 non-null     object  \n",
      " 3   right      50 non-null     object  \n",
      " 4   hand       50 non-null     category\n",
      "dtypes: category(2), object(3)\n",
      "memory usage: 1.5+ KB\n"
     ]
    }
   ],
   "source": [
    "raw_data: pd.DataFrame = pd.read_pickle(DATA_DIR / \"dataset.pkl\")\n",
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sign   hand \n",
       "when   both     10\n",
       "hello  left      5\n",
       "       right     5\n",
       "no     left      5\n",
       "       right     5\n",
       "okay   left      5\n",
       "       right     5\n",
       "yes    left      5\n",
       "       right     5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data[[\"sign\", \"hand\"]].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data for Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(left: np.ndarray, right: np.ndarray, max_frames: int) -> np.ndarray:\n",
    "    if (len(left) < max_frames):\n",
    "        increment = [np.zeros(shape=441) for _ in range(max_frames - len(left))]\n",
    "        temp_1 = np.concatenate((left, increment), axis=0)\n",
    "        temp_2 = np.concatenate((right, increment), axis=0)\n",
    "        result = np.stack((temp_1, temp_2), axis=0)\n",
    "\n",
    "    else:\n",
    "        result = np.stack((left, right), axis=0)\n",
    "\n",
    "    # return result.reshape((2,max_frames,441,1))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Frame Count: 78\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50, 2, 78, 441)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_frames = max(len(item) for item in raw_data[\"left\"])\n",
    "print(f\"Max Frame Count: {max_frames}\")\n",
    "\n",
    "X = np.array([\n",
    "    get_data(raw_data.loc[x][\"left\"], raw_data.loc[x][\"right\"], max_frames)\n",
    "    for x in range(len(raw_data))\n",
    "])\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl_enc = LabelEncoder()\n",
    "labels = lbl_enc.fit_transform(raw_data[\"sign\"])\n",
    "\n",
    "# with open(DATA_DIR / \"label_encoder.pkl\", \"wb\") as file:\n",
    "#     pkl.dump(obj=lbl_enc, file=file)\n",
    "\n",
    "Y = to_categorical(labels)\n",
    "Y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size=0.25, random_state=42, stratify=train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 2, 78, 441)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2, 78, 441)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2, 78, 441)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv3D(32, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=train_data.shape[1:]))\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "# model.add(BatchNormalization(center=True, scale=True))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Conv3D(64, kernel_size=(1, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "# model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "# model.add(BatchNormalization(center=True, scale=True))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Flatten())\n",
    "\n",
    "# model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "# model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "# model.add(Dense(train_labels.shape[1], activation='softmax'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv3D(32, kernel_size=(1, 3, 3), activation='relu', input_shape=train_data.shape[1:]))\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# model.add(Conv3D(64, kernel_size=(1, 3, 3), activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "# model.add(Flatten())\n",
    "\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dense(train_labels.shape[1], activation='softmax'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv3D(32, kernel_size=(1, 3, 3), activation='relu', input_shape=train_data.shape[1:]))\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "# model.add(Flatten())\n",
    "\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(train_labels.shape[1], activation='sigmoid'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=train_data.shape[1:], padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(train_labels.shape[1], activation='softmax'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(TimeDistributed(Conv2D(32, kernel_size=(3, 3), activation='relu'), input_shape=train_data.shape[1:]))\n",
    "# model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "\n",
    "# model.add(TimeDistributed(Conv2D(64, kernel_size=(3, 3), activation='relu')))\n",
    "# model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "\n",
    "# model.add(TimeDistributed(Conv2D(128, kernel_size=(3, 3), activation='relu')))\n",
    "# model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "\n",
    "# model.add(TimeDistributed(Conv2D(256, kernel_size=(3, 3), activation='relu')))\n",
    "# model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "# model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "# model.add(LSTM(128, activation='tanh', dropout=0.5))\n",
    "# model.add(Dense(train_labels.shape[1], activation='softmax'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 2, 78, 32)         127040    \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, 39, 32)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 1, 39, 64)         18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 1, 20, 64)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 1, 20, 128)        73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 1, 10, 128)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               327936    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 548,613\n",
      "Trainable params: 548,613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.6139 - accuracy: 0.2000 - val_loss: 1.6016 - val_accuracy: 0.2000\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 1.5438 - accuracy: 0.3667 - val_loss: 1.5964 - val_accuracy: 0.4000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 1.4005 - accuracy: 0.5333 - val_loss: 1.5969 - val_accuracy: 0.3000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 1.1968 - accuracy: 0.6667 - val_loss: 1.6376 - val_accuracy: 0.1000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.9765 - accuracy: 0.7667 - val_loss: 1.7846 - val_accuracy: 0.1000\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.7884 - accuracy: 0.7667 - val_loss: 2.0290 - val_accuracy: 0.2000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.6451 - accuracy: 0.8000 - val_loss: 2.3512 - val_accuracy: 0.4000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.5342 - accuracy: 0.8667 - val_loss: 2.7424 - val_accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.4764 - accuracy: 0.9000 - val_loss: 3.1422 - val_accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.4365 - accuracy: 0.8333 - val_loss: 3.4995 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=train_data,\n",
    "    y=train_labels,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    validation_data=(val_data, val_labels),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 70ms/step - loss: 2.5838 - accuracy: 0.7000\n",
      "Test loss: 2.583761692047119\n",
      "Test accuracy: 0.699999988079071\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
    "\n",
    "print(f\"Test loss: {test_loss}\")\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(DATA_DIR / 'model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
